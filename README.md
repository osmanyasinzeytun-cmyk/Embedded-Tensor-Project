# Bellek KÄ±sÄ±tlÄ± GÃ¶mÃ¼lÃ¼ Sistemler Ä°Ã§in Dinamik TensÃ¶r (Dynamic Tensor) GerÃ§eklemesi

## ğŸ“Œ Projenin AmacÄ±

TinyML ve gÃ¶mÃ¼lÃ¼ yapay zeka uygulamalarÄ±nda Arduino ve ESP32 gibi mikrodenetleyiciler Ã§ok sÄ±nÄ±rlÄ± RAM kapasitesine sahiptir (genellikle 320KB â€“ 520KB).

Standart 32-bit float dizileri kullanÄ±ldÄ±ÄŸÄ±nda bellek hÄ±zla tÃ¼kenir.
Bu nedenle yapay zeka modellerinde **quantization (nicemleme)** ve dÃ¼ÅŸÃ¼k hassasiyetli veri tipleri kullanÄ±lÄ±r.

Bu projede C dili kullanÄ±larak aÅŸaÄŸÄ±daki veri tiplerini **tek bir tensÃ¶r yapÄ±sÄ± iÃ§inde dinamik olarak saklayabilen** dÃ¼ÅŸÃ¼k seviyeli bir tensÃ¶r yapÄ±sÄ± tasarlanmÄ±ÅŸtÄ±r:

* Float32 (yÃ¼ksek hassasiyet)
* Float16 (orta hassasiyet)
* Int8 Quantized (dÃ¼ÅŸÃ¼k hassasiyet â€“ bellek optimize)

AmaÃ§, Python kÃ¼tÃ¼phanelerindeki (TensorFlow / PyTorch) tensÃ¶r mantÄ±ÄŸÄ±nÄ±n gÃ¶mÃ¼lÃ¼ sistemlerdeki primitive karÅŸÄ±lÄ±ÄŸÄ±nÄ± oluÅŸturmaktÄ±r.

---

## ğŸ§  TensÃ¶r Nedir?

TensÃ¶r, makine Ã¶ÄŸrenmesi modellerinde kullanÄ±lan Ã§ok boyutlu veri tutucudur.

KullanÄ±m alanlarÄ±:

* GiriÅŸ verileri
* AÄŸÄ±rlÄ±klar (weights)
* Ã–zellik haritalarÄ± (feature maps)
* Ara katman Ã§Ä±ktÄ±larÄ±

Ãœst seviye dillerde soyut bir veri yapÄ±sÄ±dÄ±r.
GÃ¶mÃ¼lÃ¼ sistemlerde ise doÄŸrudan bellek yÃ¶netimi ile manuel olarak oluÅŸturulmalÄ±dÄ±r.

Bu projede C dili kullanÄ±larak ilkel (primitive) bir tensÃ¶r gerÃ§ekleÅŸtirilmiÅŸtir.

---

## ğŸ—ï¸ Sistem Mimarisi

### Dinamik TensÃ¶r YapÄ±sÄ±

```c
typedef struct {
    TensorType type;
    TensorData data;
    int size;
    float scale;
    int zero_point;
} DynamicTensor;
```

TensÃ¶r Ã§alÄ±ÅŸma zamanÄ±nda veri tipini deÄŸiÅŸtirebilir.

### Union ile Bellek PaylaÅŸÄ±mÄ±

```c
typedef union {
    float*    f32_ptr;
    uint16_t* f16_ptr;
    int8_t*   i8_ptr;
} TensorData;
```

AynÄ± anda yalnÄ±zca tek veri tipi bellekte yer kaplar â†’ RAM tasarrufu saÄŸlanÄ±r.

---

## âš™ï¸ Quantization (Nicemleme)

### Quantization Nedir?

Float deÄŸerlerin integer formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesidir.

[
q = round(float / scale) + zero_point
]

Bu yÃ¶ntem TinyML modellerinde:

* RAM kullanÄ±mÄ±nÄ± azaltÄ±r
* Flash boyutunu kÃ¼Ã§Ã¼ltÃ¼r
* Ä°ÅŸlemci yÃ¼kÃ¼nÃ¼ azaltÄ±r

### Uygulanan Ä°ÅŸlemler

* Min-Max kalibrasyonu
* Scale hesaplama
* Zero-Point hesaplama
* INT8 sÄ±nÄ±rlandÄ±rma (-128, 127)
* Dequantization hata analizi

---

## ğŸ”¬ Float16 SimÃ¼lasyonu

MasaÃ¼stÃ¼ C derleyicilerinde native float16 desteÄŸi bulunmadÄ±ÄŸÄ±ndan simÃ¼lasyon yapÄ±lmÄ±ÅŸtÄ±r.

Bu sayede hassasiyet ve bellek kullanÄ±mÄ± arasÄ±ndaki fark gÃ¶zlemlenmiÅŸtir:

Float32 > Float16 > Int8

---

## ğŸ’¾ Bellek KarÅŸÄ±laÅŸtÄ±rmasÄ±

| Veri Tipi | Eleman BaÅŸÄ±na Bellek |
| --------- | -------------------- |
| Float32   | 4 Byte               |
| Float16   | 2 Byte               |
| Int8      | 1 Byte               |

Quantization sonrasÄ± yaklaÅŸÄ±k **%75 bellek tasarrufu** elde edilir.

---

## ğŸ§ª Program Ã‡alÄ±ÅŸma AÅŸamalarÄ±

1. SensÃ¶r verisi Float32 olarak oluÅŸturulur
2. INT8 quantization uygulanÄ±r
3. Dequantization ile hata oranÄ± Ã¶lÃ§Ã¼lÃ¼r
4. Float16 simÃ¼lasyonu yapÄ±lÄ±r
5. Bellek kullanÄ±mÄ± karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r

---

## ğŸ Debugger ile Ä°nceleme

Debugger kullanÄ±larak:

* AynÄ± tensÃ¶rÃ¼n farklÄ± veri tiplerinde nasÄ±l yorumlandÄ±ÄŸÄ±
* Bellek adreslerinin deÄŸiÅŸmediÄŸi
* Veri temsilinin deÄŸiÅŸtiÄŸi

gÃ¶zlemlenebilir.

---

## ğŸ§© KullanÄ±lan Kavramlar

* Struct ve Union
* Dinamik bellek yÃ¶netimi (malloc/free)
* Tip dÃ¶nÃ¼ÅŸÃ¼mÃ¼
* Quantization
* Dequantization
* Bellek optimizasyonu

---



## ğŸ“Š SonuÃ§

Bu projede gÃ¶mÃ¼lÃ¼ sistemlerde yapay zeka modellerinin Ã§alÄ±ÅŸtÄ±rÄ±labilmesi iÃ§in gerekli olan:

* Bellek optimizasyonu
* Veri tipi esnekliÄŸi
* Quantization mantÄ±ÄŸÄ±

C dili seviyesinde baÅŸarÄ±yla gerÃ§ekleÅŸtirilmiÅŸtir.

Bu yapÄ± TinyML uygulamalarÄ±nda tensÃ¶r yÃ¶netiminin temel prensibini temsil eder.

